{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ML Train.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"r4wOyMsPm2oL","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":106},"outputId":"2a9ef683-5d46-4ce9-a2bb-23bcde970949","executionInfo":{"status":"ok","timestamp":1531549454909,"user_tz":-480,"elapsed":17590,"user":{"displayName":"2017 Dody Senputra","photoUrl":"//lh5.googleusercontent.com/-hdFUvUrEsO4/AAAAAAAAAAI/AAAAAAAAAA0/Bl_n1jyd3zo/s50-c-k-no/photo.jpg","userId":"100496414587395031393"}}},"cell_type":"code","source":["### Run this to be able to access your drive. Google will ask you to input a verification code twice. Just do so\n","\n","!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\r\n","··········\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","Please enter the verification code: Access token retrieved correctly.\n"],"name":"stdout"}]},{"metadata":{"id":"yyHy9LIagqyo","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"vkOdyJIjpNP5","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":86},"outputId":"48e746b7-ea5c-43c4-ac82-ac2de8d95ab9","executionInfo":{"status":"ok","timestamp":1531549472437,"user_tz":-480,"elapsed":5246,"user":{"displayName":"2017 Dody Senputra","photoUrl":"//lh5.googleusercontent.com/-hdFUvUrEsO4/AAAAAAAAAAI/AAAAAAAAAA0/Bl_n1jyd3zo/s50-c-k-no/photo.jpg","userId":"100496414587395031393"}}},"cell_type":"code","source":["## Ensure your drive contains the folder ML Captcha at this bottom address. Run this to test if it really is there.\n","\n","!mkdir -p drive\n","!google-drive-ocamlfuse drive\n","import os\n","os.chdir(\"/content/drive/ML Captcha\")\n","!ls"],"execution_count":3,"outputs":[{"output_type":"stream","text":["drive\t\t     ML_model_labels (temp).dat  Quicksand-Regular.otf\r\n","ML_Data_Quicksand    ML Train.ipynb\t\t Test_ML_Model.ipynb\r\n","ML_model.hdf5\t     Modified_Claptcha_Lib.py\r\n","ML_model_labels.dat  __pycache__\r\n"],"name":"stdout"}]},{"metadata":{"id":"fOeLtPD-qeyB","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["### Generates (3) Claptcha images (modified) for each letter, each 20x20. To change number of Claptcha images per letter, {ctrl+F, type 9908}\n","\n","import sys\n","import os\n","import random\n","from functools import wraps\n","from io import BytesIO\n","from PIL import Image, ImageDraw, ImageFont\n","import cv2\n","import numpy\n","\n","##########################################################################################################\n","##########################################################################################################\n","##########################################################################################################\n","#################################### Clapcha Library starts ##############################################\n","##########################################################################################################\n","##########################################################################################################\n","##########################################################################################################\n","\n","class ClaptchaError(Exception):\n","    \"\"\"Exception class for Claptcha errors.\"\"\"\n","\n","    pass\n","\n","\n","class Claptcha(object):\n","    r\"\"\"\n","    Claptcha class.\n","    Claptcha can be use to create PIL Images, BytesIO objects and image\n","    files with CAPTCHA messages. User has to provide at least a source\n","    (a string containing text used in CAPTCHA image or a callable object\n","    returning a string) and a filepath to TTF font file.\n","    Additionally, Claptcha allows to define image size and estimated\n","    margins, used in automatically calculating font size. By default,\n","    Claptcha generates a PNG image using bicubic resampling filter\n","    (configurable).\n","    Optionally, user can define white noise, making it less readable for\n","    OCR software. However, this significantly extends execution time of\n","    image creation.\n","    \"\"\"\n","\n","    def __init__(self, source, font,\n","                 size=(20, 20), margin=(3, 3),\n","                 **kwargs):\n","        r\"\"\"\n","        Claptcha object init.\n","        Claptcha object requires at least a text source (a string or a\n","        callable object returning a string) and a path to a TTF file. Both\n","        are used in generating text in returned CAPTCHA image with a given\n","        font. Callable object allow for creating variable CAPTCHAs without\n","        redeclaring Claptcha instance, e.g. a randomized stream of characters\n","        :param source:\n","            String or a callable object returning a string.\n","        :param font:\n","            Valid path (relative or absolute) to a TTF file.\n","        :param size:\n","            A pair with CAPTCHA size (width, height)\n","            in pixels.\n","        :param margin:\n","            A pair with CAPTCHA x and y margins in pixels\n","            Note that generated text may slightly overlap\n","            given margins, you should treat them only as\n","            an estimate.\n","        :param \\**kwargs:\n","            See below\n","        :Keyword Arguments:\n","            * *format* (``string``) --\n","              Image format acceptable by Image class from PIL package.\n","            * *resample* (``int``) --\n","              Resampling filter. Allowed: Image.NEAREST, Image.BILINEAR and\n","              Image.BICUBIC. Default: Image.BILINEAR.\n","            * *noise* (``float``) --\n","              Parameter from range [0,1] used in creating noise effect in\n","              CAPTCHA image. If not larger than 1/255, no noise if generated.\n","              It is advised to not use this option if you want to focus on\n","              efficiency, since generating noise can significantly extend\n","              image creation time. Default: 0.\n","        \"\"\"\n","        self.source = source\n","        self.size = size\n","        self.margin = margin\n","        self.font = font\n","\n","        self.format = kwargs.get('format', 'PNG')\n","        self.resample = kwargs.get('resample', Image.BILINEAR)\n","        self.noise = abs(kwargs.get('noise', 0.))\n","\n","    @property\n","    def image(self):\n","        r\"\"\"\n","        Tuple with a CAPTCHA text and a Image object.\n","        Images are generated on the fly, using given text source, TTF font and\n","        other parameters passable through __init__. All letters in used text\n","        are morphed. Also a line is morphed and pased onto CAPTCHA text.\n","        Additionaly, if self.noise > 1/255, a \"snowy\" image is merged with\n","        CAPTCHA image with a 50/50 ratio.\n","        Property returns a pair containing a string with text in returned\n","        image and image itself.\n","        :returns: ``tuple`` (CAPTCHA text, Image object)\n","        \"\"\"\n","        text = self.text\n","        w, h = self.font.getsize(text)\n","        margin_x = round(self.margin_x * w / self.w)\n","        margin_y = round(self.margin_y * h / self.h)\n","\n","        image = Image.new('RGB',\n","                          (w + 2*margin_x, h + 2*margin_y),\n","                          (255, 255, 255))\n","\n","        # Text\n","        self._writeText(image, text, pos=(margin_x, margin_y))\n","\n","\n","        # White noise\n","        noise = self._whiteNoise(image.size)\n","        if noise is not None:\n","            image = Image.blend(image, noise, 0.5)\n","\n","        # Resize\n","        image = image.resize(self.size, resample=self.resample)\n","\n","        return (text, image)\n","\n","    @property\n","    def bytes(self):\n","        r\"\"\"\n","        Tuple with a CAPTCHA text and a BytesIO object.\n","        Property calls self.image and saves image contents in a BytesIO\n","        instance, returning CAPTCHA text and BytesIO as a tuple.\n","        See: image.\n","        :returns: ``tuple`` (CAPTCHA text, BytesIO object)\n","        \"\"\"\n","        text, image = self.image\n","        bytes = BytesIO()\n","        image.save(bytes, format=self.format)\n","        bytes.seek(0)\n","        return (text, bytes)\n","\n","    def write(self, file):\n","        r\"\"\"\n","        Save CAPTCHA image in given filepath.\n","        Property calls self.image and saves image contents in a file,\n","        returning CAPTCHA text and filepath as a tuple.\n","        See: image.\n","        :param file:\n","            Path to file, where CAPTCHA image will be saved.\n","        :returns: ``tuple`` (CAPTCHA text, filepath)\n","        \"\"\"\n","        text, image = self.image\n","        image.save(file, format=self.format)\n","        return (text, file)\n","\n","    @property\n","    def source(self):\n","        \"\"\"Text source, either a string or a callable object.\"\"\"\n","        return self.__source\n","\n","    @source.setter\n","    def source(self, source):\n","        if not (isinstance(source, str) or callable(source)):\n","            raise ClaptchaError(\"source has to be either a string or be callable\")\n","        self.__source = source\n","\n","    @property\n","    def text(self):\n","        \"\"\"Text received from self.source.\"\"\"\n","        if isinstance(self.source, str):\n","            return self.source\n","        else:\n","            return self.source()\n","\n","    def _with_pair_validator(func):\n","        @wraps(func)\n","        def wrapper(inst, pair):\n","            if not (hasattr(pair, '__len__') and hasattr(pair, '__getitem__')):\n","                raise ClaptchaError(\"Sequence not provided\")\n","            if len(pair) != 2:\n","                raise ClaptchaError(\"Sequence has to have exactly 2 elements\")\n","            return func(inst, pair)\n","        return wrapper\n","\n","    @property\n","    def size(self):\n","        \"\"\"CAPTCHA image size.\"\"\"\n","        return self.__size\n","\n","    @size.setter\n","    @_with_pair_validator\n","    def size(self, size):\n","        self.__size = (int(size[0]), int(size[1]))\n","\n","    @property\n","    def w(self):\n","        \"\"\"CAPTCHA image width.\"\"\"\n","        return self.size[0]\n","\n","    @property\n","    def h(self):\n","        \"\"\"CAPTCHA image height.\"\"\"\n","        return self.size[1]\n","\n","    @property\n","    def margin(self):\n","        \"\"\"CAPTCHA image estimated margin.\"\"\"\n","        return self.__margin\n","\n","    @margin.setter\n","    @_with_pair_validator\n","    def margin(self, margin):\n","        if 2*margin[1] > self.h:\n","            raise ClaptchaError(\"Margin y cannot be larger than half of image height.\")\n","        self.__margin = (int(margin[0]), int(margin[1]))\n","\n","    @property\n","    def margin_x(self):\n","        \"\"\"CAPTCHA image estimated x margin.\"\"\"\n","        return self.__margin[0]\n","\n","    @property\n","    def margin_y(self):\n","        \"\"\"CAPTCHA image estimated y margin.\"\"\"\n","        return self.__margin[1]\n","\n","    def _with_file_validator(func):\n","        @wraps(func)\n","        def wrapper(inst, file):\n","            if not isinstance(file, ImageFont.ImageFont):\n","                if not os.path.exists(file):\n","                    raise ClaptchaError(\"%s doesn't exist\" % (file,))\n","                if not os.path.isfile(file):\n","                    raise ClaptchaError(\"%s is not a file\" % (file,))\n","            return func(inst, file)\n","        return wrapper\n","\n","    @property\n","    def font(self):\n","        \"\"\"ImageFont object from PIL package.\"\"\"\n","        return self.__font\n","\n","    @font.setter\n","    @_with_file_validator\n","    def font(self, font):\n","        if isinstance(font, ImageFont.ImageFont):\n","            self.__font = font\n","        else:\n","            fontsize = self.h - 2 * self.margin_y\n","            self.__font = ImageFont.truetype(font, fontsize)\n","\n","    @property\n","    def noise(self):\n","        \"\"\"Noise parameter from [0,1].\"\"\"\n","        return self.__noise\n","\n","    @noise.setter\n","    def noise(self, noise):\n","        if noise < 0. or noise > 1.:\n","            raise ClaptchaError(\"only acceptable noise amplitude from range [0:1]\")\n","        self.__noise = noise\n","\n","    def _writeText(self, image, text, pos):\n","        \"\"\"Write morphed text in Image object.\"\"\"\n","        offset = 0\n","        x, y = pos\n","\n","        for c in text:\n","            # Write letter\n","            c_size = self.font.getsize(c)\n","            c_image = Image.new('RGBA', c_size, (0, 0, 0, 0))\n","            c_draw = ImageDraw.Draw(c_image)\n","            c_draw.text((0, 0), c, font=self.font, fill=(0, 0, 0, 255))\n","\n","            # Transform\n","            c_image = self._rndLetterTransform(c_image)\n","\n","            # Paste onto image\n","            image.paste(c_image, (x+offset, y), c_image)\n","            offset += c_size[0]\n","\n","    def _drawLine(self, image):\n","        \"\"\"Draw morphed line in Image object.\"\"\"\n","        w, h = image.size\n","        w *= 5\n","        h *= 5\n","\n","        l_image = Image.new('RGBA', (w, h), (0, 0, 0, 0))\n","        l_draw = ImageDraw.Draw(l_image)\n","\n","        x1 = int(w * random.uniform(0, 0.1))\n","        y1 = int(h * random.uniform(0, 1))\n","        x2 = int(w * random.uniform(0.9, 1))\n","        y2 = int(h * random.uniform(0, 1))\n","\n","        # Line width modifier was chosen as an educated guess\n","        # based on default image area.\n","        l_width = round((w * h)**0.5 * 2.284e-2)\n","\n","        # Draw\n","        l_draw.line(((x1, y1), (x2, y2)), fill=(0, 0, 0, 255), width=l_width)\n","\n","        # Transform\n","        l_image = self._rndLineTransform(l_image)\n","        l_image = l_image.resize(image.size, resample=self.resample)\n","\n","        # Paste onto image\n","        image.paste(l_image, (0, 0), l_image)\n","\n","    def _whiteNoise(self, size):\n","        \"\"\"Generate white noise and merge it with given Image object.\"\"\"\n","        if self.noise > 0.003921569:  # 1./255.\n","            w, h = size\n","\n","            pixel = (lambda noise: round(255 * random.uniform(1-noise, 1)))\n","\n","            n_image = Image.new('RGB', size, (0, 0, 0, 0))\n","            rnd_grid = map(lambda _: tuple([pixel(self.noise)]) * 3,\n","                           [0] * w * h)\n","            n_image.putdata(list(rnd_grid))\n","            return n_image\n","        else:\n","            return None\n","\n","    def _rndLetterTransform(self, image):\n","        \"\"\"Randomly morph a single character.\"\"\"\n","        w, h = image.size\n","\n","        dx = w * random.uniform(0.2, 0.5)\n","        dy = h * random.uniform(0.2, 0.5)\n","\n","        x1, y1 = self.__class__._rndPointDisposition(dx, dy)\n","        x2, y2 = self.__class__._rndPointDisposition(dx, dy)\n","\n","        w += abs(x1) + abs(x2)\n","        h += abs(x1) + abs(x2)\n","\n","        quad = self.__class__._quadPoints((w, h), (x1, y1), (x2, y2))\n","\n","        return image.transform(image.size, Image.QUAD,\n","                               data=quad, resample=self.resample)\n","\n","    def _rndLineTransform(self, image):\n","        \"\"\"Randomly morph Image object with drawn line.\"\"\"\n","        w, h = image.size\n","\n","        dx = h * random.uniform(0.2, 0.5)\n","        dy = w * random.uniform(0.2, 0.5)\n","\n","        x1, y1 = [abs(z) for z in self.__class__._rndPointDisposition(dx, dy)]\n","        x2, y2 = [abs(z) for z in self.__class__._rndPointDisposition(dx, dy)]\n","\n","        quad = self.__class__._quadPoints((w, h), (x1, y1), (x2, y2))\n","\n","        return image.transform(image.size, Image.QUAD,\n","                               data=quad, resample=self.resample)\n","\n","    @staticmethod\n","    def _rndPointDisposition(dx, dy):\n","        \"\"\"Return random disposition point.\"\"\"\n","        x = int(random.uniform(-dx, dx))\n","        y = int(random.uniform(-dy, dy))\n","        return (x, y)\n","\n","    @staticmethod\n","    def _quadPoints(size, disp1, disp2):\n","        \"\"\"Return points for QUAD transformation.\"\"\"\n","        w, h = size\n","        x1, y1 = disp1\n","        x2, y2 = disp2\n","\n","        return (\n","            x1,    -y1,\n","            -x1,    h + y2,\n","            w + x2, h - y2,\n","            w - x2, y1\n","        )\n","      \n","##########################################################################################################\n","##########################################################################################################\n","##########################################################################################################\n","#################################### Clapcha Library ends ################################################\n","##########################################################################################################\n","##########################################################################################################\n","##########################################################################################################\n","\n","\n","\n","# ake folder for data\n","newpath = r'/content/drive/ML Captcha/ML_Data_Quicksand' \n","if not os.path.exists(newpath): # Creates new directory if it does not exists\n","    os.makedirs(newpath)\n","\n","CHARS = \"QWERTYUIOPASDFGHJKLZXCVBNM\" # Character list for Claptcha\n","\n","for char in CHARS:\n","    for number in range (0,50): # <- Number of images per letter 9908\n","\n","        Text = char\n","\n","        # Initialize Claptcha object with \"Text\" as text and <> as font\n","        c = Claptcha(Text, \"/content/drive/ML Captcha/Quicksand-Regular.otf\")\n","\n","        # Get PIL Image object\n","        text, image = c.image\n","        \n","        # Grayscale, threshold and invert image\n","        image = cv2.cvtColor(numpy.array(image), cv2.COLOR_BGR2GRAY)\n","        image = cv2.threshold(image, 200, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n","        image = cv2.bitwise_not(image)\n","\n","        # Generates folders for each letter\n","        save_path = '/content/drive/ML Captcha/ML_Data_Quicksand/'\n","        savepath = os.path.join(save_path, char)\n","        if not os.path.exists(savepath):\n","            os.makedirs(savepath)\n","\n","        # Save a PNG file '<no.>.png' into corresponding folder\n","        im = Image.fromarray(image)\n","        im.save(os.path.join(save_path, char)+'/'+str(number)+'.png')\n","        \n","        # Verbose mode\n","        ##print(os.path.join(save_path, char)+'/'+str(number)+'.png is created')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"BDyB75J5t_nN","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":156},"outputId":"3156aac8-b5a0-417f-9853-91acad96598d","executionInfo":{"status":"ok","timestamp":1531566346958,"user_tz":-480,"elapsed":575545,"user":{"displayName":"2017 Poon Zong Wei Julian","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"104806765094541702931"}}},"cell_type":"code","source":["### Train Model\n","### Heavily copied from https://medium.com/@ageitgey/how-to-break-a-captcha-system-in-15-minutes-with-machine-learning-dbebb035a710\n","\n","import cv2\n","import pickle\n","import os.path\n","import numpy as np\n","from sklearn.preprocessing import LabelBinarizer\n","from sklearn.model_selection import train_test_split\n","from keras.models import Sequential\n","from keras.layers.convolutional import Conv2D, MaxPooling2D\n","from keras.layers.core import Flatten, Dense\n","\n","FOLDER = \"/content/drive/ML Captcha/\"\n","\n","# Initialise paths\n","LETTER_IMAGES_FOLDER = FOLDER + \"ML_Data_Quicksand\"\n","MODEL_FILENAME = FOLDER + \"ML_model (temp).hdf5\"\n","MODEL_LABELS_FILENAME = FOLDER + \"ML_model_labels (temp).dat\"\n","\n","\n","# initialize the data and labels\n","data = []\n","labels = []\n","\n","LETTER_IMAGES_FOLDER = FOLDER + \"ML_Data_Quicksand\"\n","\n","# loop over the input images\n","for folder in os.listdir(LETTER_IMAGES_FOLDER):\n","  for file in os.listdir(LETTER_IMAGES_FOLDER+\"/\"+folder):\n","    # Load the image and convert it to grayscale\n","    image = cv2.imread(LETTER_IMAGES_FOLDER+\"/\"+folder+\"/\"+file)\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","    # Add a third channel dimension to the image to make Keras happy\n","    image = np.expand_dims(image, axis=2)\n","\n","    # Grab the name of the letter based on the folder it was in\n","    label = folder\n","    #print (label) #<-- Just for me to test ^.^\n","\n","    # Add the letter image and it's label to our training data\n","    data.append(image)\n","    labels.append(label)\n","\n","\n","# scale the raw pixel intensities to the range [0, 1] (this improves training)\n","data = np.array(data, dtype=\"float\") / 255.0\n","labels = np.array(labels)\n","print (labels)\n","\n","# Split the training data into separate train and test sets\n","(X_train, X_test, Y_train, Y_test) = train_test_split(data, labels, test_size=0.25, random_state=0)\n","\n","# Convert the labels (letters) into one-hot encodings that Keras can work with\n","lb = LabelBinarizer().fit(Y_train)\n","Y_train = lb.transform(Y_train)\n","Y_test = lb.transform(Y_test)\n","\n","# Save the mapping from labels to one-hot encodings.\n","# We'll need this later when we use the model to decode what it's predictions mean\n","with open(MODEL_LABELS_FILENAME, \"wb\") as f:\n","    pickle.dump(lb, f)\n","\n","# Build the neural network!\n","model = Sequential()\n","\n","# First convolutional layer with max pooling\n","model.add(Conv2D(20, (5, 5), padding=\"same\", input_shape=(20, 20, 1), activation=\"relu\"))\n","model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","\n","# Second convolutional layer with max pooling\n","model.add(Conv2D(50, (5, 5), padding=\"same\", activation=\"relu\"))\n","model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","\n","# Hidden layer with 500 nodes\n","model.add(Flatten())\n","model.add(Dense(500, activation=\"relu\"))\n","\n","# Output layer with 26 nodes (one for each possible letter we predict, 26 letters)\n","model.add(Dense(26, activation=\"softmax\"))\n","\n","# Ask Keras to build the TensorFlow model behind the scenes\n","model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n","\n","# Train the neural network\n","model.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size=26, epochs=3, verbose=1)\n","\n","# Save the trained model to disk\n","model.save(MODEL_FILENAME)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["['Q' 'Q' 'Q' ... 'M' 'M' 'M']\n","Train on 975 samples, validate on 325 samples\n","Epoch 1/3\n","975/975 [==============================] - 2s 2ms/step - loss: 3.2006 - acc: 0.0903 - val_loss: 3.0091 - val_acc: 0.2031\n","Epoch 2/3\n","975/975 [==============================] - 2s 2ms/step - loss: 2.0693 - acc: 0.4841 - val_loss: 1.0956 - val_acc: 0.7046\n","Epoch 3/3\n","975/975 [==============================] - 2s 2ms/step - loss: 0.6958 - acc: 0.8103 - val_loss: 0.5762 - val_acc: 0.8246\n"],"name":"stdout"}]},{"metadata":{"id":"0mmLEu4Ebps9","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["## Convert from h5 to pb (need to run session above first)\n","\n","######################################################################################################################\n","######################################################################################################################\n","############################################## Convert from h5 to pb #################################################\n","######################################################################################################################\n","######################################################################################################################\n","\n","#### Code from https://stackoverflow.com/questions/45466020/how-to-export-keras-h5-to-tensorflow-pb\n","\n","def freeze_session(session, keep_var_names=None, output_names=None, clear_devices=True):\n","    \"\"\"\n","    Freezes the state of a session into a pruned computation graph.\n","\n","    Creates a new computation graph where variable nodes are replaced by\n","    constants taking their current value in the session. The new graph will be\n","    pruned so subgraphs that are not necessary to compute the requested\n","    outputs are removed.\n","    @param session The TensorFlow session to be frozen.\n","    @param keep_var_names A list of variable names that should not be frozen,\n","                          or None to freeze all the variables in the graph.\n","    @param output_names Names of the relevant graph outputs.\n","    @param clear_devices Remove the device directives from the graph for better portability.\n","    @return The frozen graph definition.\n","    \"\"\"\n","    from tensorflow.python.framework.graph_util import convert_variables_to_constants\n","    graph = session.graph\n","    with graph.as_default():\n","        freeze_var_names = list(set(v.op.name for v in tf.global_variables()).difference(keep_var_names or []))\n","        output_names = output_names or []\n","        output_names += [v.op.name for v in tf.global_variables()]\n","        input_graph_def = graph.as_graph_def()\n","        if clear_devices:\n","            for node in input_graph_def.node:\n","                node.device = \"\"\n","        frozen_graph = convert_variables_to_constants(session, input_graph_def,\n","                                                      output_names, freeze_var_names)\n","        return frozen_graph\n","\n","frozen_graph = freeze_session(K.get_session(),\n","                              output_names=[out.op.name for out in model.outputs])\n","\n","tf.train.write_graph(frozen_graph, FOLDER, \"ML_model_test.pb\", as_text=False)"],"execution_count":0,"outputs":[]}]}